{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a12d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ca8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=500\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb71889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae1d901b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinny\\anaconda3\\envs\\rl-learn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf3c8c",
   "metadata": {},
   "source": [
    "### CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0cfb237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinny\\anaconda3\\envs\\rl-learn\\lib\\site-packages\\gym\\envs\\atari\\environment.py:269: UserWarning: \u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "  \"We strongly suggest supplying `render_mode` when \"\n",
      "C:\\Users\\sinny\\anaconda3\\envs\\rl-learn\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:434: UserWarning: [WinError -2147417850] 스레드 모드가 설정된 후에는 바꿀 수 없습니다\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "7\n",
      "6\n",
      "2\n",
      "8\n",
      "6\n",
      "8\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "8\n",
      "2\n",
      "3\n",
      "6\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "2\n",
      "7\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "7\n",
      "7\n",
      "5\n",
      "6\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "6\n",
      "1\n",
      "3\n",
      "8\n",
      "3\n",
      "4\n",
      "6\n",
      "3\n",
      "7\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "4\n",
      "3\n",
      "2\n",
      "5\n",
      "6\n",
      "8\n",
      "5\n",
      "5\n",
      "8\n",
      "4\n",
      "3\n",
      "1\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "0\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "8\n",
      "6\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "1\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "6\n",
      "6\n",
      "7\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "0\n",
      "3\n",
      "6\n",
      "2\n",
      "5\n",
      "6\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "0\n",
      "3\n",
      "0\n",
      "5\n",
      "6\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n",
      "2\n",
      "0\n",
      "8\n",
      "5\n",
      "5\n",
      "8\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "4\n",
      "3\n",
      "7\n",
      "1\n",
      "3\n",
      "6\n",
      "1\n",
      "6\n",
      "1\n",
      "1\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "6\n",
      "7\n",
      "0\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "7\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "1\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "6\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "8\n",
      "3\n",
      "3\n",
      "6\n",
      "8\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "5\n",
      "3\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "1\n",
      "0\n",
      "5\n",
      "4\n",
      "8\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "1\n",
      "6\n",
      "2\n",
      "1\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "4\n",
      "3\n",
      "8\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "8\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "7\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "4\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "8\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "8\n",
      "6\n",
      "3\n",
      "5\n",
      "7\n",
      "8\n",
      "6\n",
      "5\n",
      "3\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "0\n",
      "5\n",
      "5\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "5\n",
      "0\n",
      "2\n",
      "6\n",
      "5\n",
      "5\n",
      "3\n",
      "8\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "3\n",
      "6\n",
      "7\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "7\n",
      "5\n",
      "5\n",
      "2\n",
      "0\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "3\n",
      "3\n",
      "8\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "1\n",
      "3\n",
      "3\n",
      "6\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "7\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "7\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "8\n",
      "5\n",
      "3\n",
      "7\n",
      "1\n",
      "5\n",
      "0\n",
      "2\n",
      "6\n",
      "5\n",
      "5\n",
      "1\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "8\n",
      "2\n",
      "7\n",
      "5\n",
      "3\n",
      "6\n",
      "7\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "7\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "6\n",
      "8\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "1\n",
      "3\n",
      "6\n",
      "7\n",
      "3\n",
      "1\n",
      "5\n",
      "6\n",
      "0\n",
      "3\n",
      "3\n",
      "7\n",
      "6\n",
      "6\n",
      "0\n",
      "3\n",
      "5\n",
      "8\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "7\n",
      "3\n",
      "6\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "-1400\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "8\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "1\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "4\n",
      "1\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "7\n",
      "5\n",
      "3\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "7\n",
      "5\n",
      "8\n",
      "8\n",
      "5\n",
      "3\n",
      "7\n",
      "3\n",
      "1\n",
      "8\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "8\n",
      "4\n",
      "3\n",
      "6\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "0\n",
      "2\n",
      "6\n",
      "3\n",
      "7\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "6\n",
      "2\n",
      "6\n",
      "8\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "4\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "1\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "8\n",
      "6\n",
      "8\n",
      "1\n",
      "3\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "8\n",
      "1\n",
      "1\n",
      "2\n",
      "6\n",
      "2\n",
      "8\n",
      "6\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "0\n",
      "6\n",
      "8\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "3\n",
      "6\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "0\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "5\n",
      "1\n",
      "5\n",
      "3\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "4\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "3\n",
      "8\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "1\n",
      "8\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "7\n",
      "7\n",
      "4\n",
      "6\n",
      "6\n",
      "1\n",
      "3\n",
      "5\n",
      "3\n",
      "1\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "1\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "6\n",
      "3\n",
      "4\n",
      "6\n",
      "0\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "7\n",
      "4\n",
      "2\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "1\n",
      "8\n",
      "0\n",
      "3\n",
      "7\n",
      "0\n",
      "6\n",
      "6\n",
      "3\n",
      "7\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "0\n",
      "3\n",
      "1\n",
      "8\n",
      "3\n",
      "3\n",
      "1\n",
      "4\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "6\n",
      "5\n",
      "6\n",
      "2\n",
      "3\n",
      "6\n",
      "1\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "1\n",
      "3\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "3\n",
      "1\n",
      "7\n",
      "0\n",
      "6\n",
      "6\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "4\n",
      "5\n",
      "2\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "4\n",
      "0\n",
      "6\n",
      "0\n",
      "6\n",
      "7\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "3\n",
      "7\n",
      "7\n",
      "8\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "6\n",
      "3\n",
      "6\n",
      "0\n",
      "3\n",
      "8\n",
      "5\n",
      "1\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "8\n",
      "1\n",
      "3\n",
      "6\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "4\n",
      "8\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "6\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "3\n",
      "8\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "8\n",
      "6\n",
      "0\n",
      "1\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "3\n",
      "3\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "5\n",
      "6\n",
      "3\n",
      "2\n",
      "6\n",
      "5\n",
      "1\n",
      "5\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "1\n",
      "6\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n",
      "8\n",
      "6\n",
      "8\n",
      "7\n",
      "8\n",
      "4\n",
      "7\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "1\n",
      "6\n",
      "5\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "7\n",
      "3\n",
      "4\n",
      "6\n",
      "8\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "4\n",
      "7\n",
      "5\n",
      "3\n",
      "8\n",
      "3\n",
      "6\n",
      "6\n",
      "0\n",
      "6\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "8\n",
      "3\n",
      "6\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "5\n",
      "6\n",
      "2\n",
      "6\n",
      "5\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "7\n",
      "3\n",
      "3\n",
      "7\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "4\n",
      "7\n",
      "0\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "0\n",
      "3\n",
      "7\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "1\n",
      "-900\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "0\n",
      "7\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "1\n",
      "5\n",
      "1\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "7\n",
      "8\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "4\n",
      "0\n",
      "7\n",
      "3\n",
      "6\n",
      "5\n",
      "7\n",
      "0\n",
      "4\n",
      "5\n",
      "8\n",
      "3\n",
      "2\n",
      "2\n",
      "7\n",
      "8\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "4\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "8\n",
      "2\n",
      "6\n",
      "3\n",
      "7\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "6\n",
      "3\n",
      "6\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "1\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n",
      "6\n",
      "3\n",
      "2\n",
      "7\n",
      "7\n",
      "4\n",
      "3\n",
      "1\n",
      "6\n",
      "1\n",
      "6\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "3\n",
      "5\n",
      "7\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "2\n",
      "8\n",
      "6\n",
      "6\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n",
      "5\n",
      "8\n",
      "1\n",
      "6\n",
      "6\n",
      "7\n",
      "1\n",
      "6\n",
      "5\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "0\n",
      "6\n",
      "6\n",
      "7\n",
      "0\n",
      "8\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "1\n",
      "6\n",
      "0\n",
      "7\n",
      "6\n",
      "7\n",
      "1\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "8\n",
      "3\n",
      "2\n",
      "3\n",
      "8\n",
      "8\n",
      "3\n",
      "5\n",
      "7\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "7\n",
      "2\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "8\n",
      "1\n",
      "7\n",
      "5\n",
      "6\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "7\n",
      "6\n",
      "6\n",
      "1\n",
      "1\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "1\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "6\n",
      "2\n",
      "6\n",
      "1\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "1\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n",
      "1\n",
      "7\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "0\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "6\n",
      "8\n",
      "3\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "6\n",
      "0\n",
      "6\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "2\n",
      "4\n",
      "4\n",
      "6\n",
      "1\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "6\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "5\n",
      "3\n",
      "0\n",
      "1\n",
      "6\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "0\n",
      "4\n",
      "8\n",
      "3\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "8\n",
      "0\n",
      "0\n",
      "2\n",
      "6\n",
      "6\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "5\n",
      "6\n",
      "5\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "6\n",
      "0\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "1\n",
      "3\n",
      "6\n",
      "7\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "7\n",
      "2\n",
      "5\n",
      "3\n",
      "5\n",
      "1\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "1\n",
      "6\n",
      "5\n",
      "3\n",
      "7\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "0\n",
      "7\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      "5\n",
      "3\n",
      "3\n",
      "8\n",
      "2\n",
      "6\n",
      "7\n",
      "1\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "8\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "1\n",
      "8\n",
      "3\n",
      "0\n",
      "6\n",
      "8\n",
      "3\n",
      "6\n",
      "5\n",
      "4\n",
      "8\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "8\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "7\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "8\n",
      "6\n",
      "0\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "5\n",
      "8\n",
      "7\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "8\n",
      "8\n",
      "6\n",
      "3\n",
      "2\n",
      "8\n",
      "6\n",
      "5\n",
      "6\n",
      "0\n",
      "0\n",
      "6\n",
      "8\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36644\\1536626043.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36644\\1536626043.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[0mstate_prime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36644\\1536626043.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, state, epsilon)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_policy_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\rl-learn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36644\\1536626043.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "HyperParameter = collections.namedtuple('HyperParameter',\n",
    "                                        ['batch_size', 'gamma', 'learning_rate', 'buffer_limit'])\n",
    "\n",
    "\n",
    "class Qnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self._conv1 = nn.Conv2d(in_channels=3,\n",
    "                                out_channels=16,\n",
    "                                kernel_size=8,\n",
    "                                stride=4,\n",
    "                                device=device)\n",
    "\n",
    "        self._bn1 = nn.BatchNorm2d(16, device=device)\n",
    "\n",
    "        self._conv2 = nn.Conv2d(in_channels=16,\n",
    "                                out_channels=32,\n",
    "                                kernel_size=4,\n",
    "                                stride=2,\n",
    "                                device=device)\n",
    "\n",
    "        self._bn2 = nn.BatchNorm2d(32,\n",
    "                                   device=device)\n",
    "\n",
    "        self._ln1 = nn.Linear(2592, 256,\n",
    "                              device=device)\n",
    "        self._ln2 = nn.Linear(256, 9,\n",
    "                              device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self._bn1(self._conv1(x)))\n",
    "        x = F.relu(self._bn2(self._conv2(x)))\n",
    "\n",
    "        x = x.view(-1) if x.dim() == 3 else x.view(x.shape[0], -1)\n",
    "\n",
    "        x = F.relu(self._ln1(x))\n",
    "        x = self._ln2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, buffer_limit):\n",
    "        self._buffer = collections.deque(maxlen=buffer_limit)\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._buffer)\n",
    "\n",
    "    def put(self, state, state_prime, action, reward, done):\n",
    "        self._buffer.append((state, state_prime, action, reward, done))\n",
    "\n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self._buffer, n)\n",
    "        state_list, action_list, reward_list, state_prime_list, done_mask_list = [], [], [], [], []\n",
    "\n",
    "        for transition in mini_batch:\n",
    "            state, state_prime, action, reward, done_mask = transition\n",
    "\n",
    "            state_list.append(state)\n",
    "            action_list.append([action])\n",
    "            reward_list.append([reward])\n",
    "            state_prime_list.append(state_prime)\n",
    "            done_mask_list.append([done_mask])\n",
    "\n",
    "        return torch.stack(state_list), torch.tensor(action_list), \\\n",
    "               torch.tensor(reward_list), torch.stack(state_prime_list), \\\n",
    "               torch.tensor(done_mask_list)\n",
    "\n",
    "    def reset(self):\n",
    "        self._buffer.clear()\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, param: HyperParameter, path=None):\n",
    "        self._PARAMETER = param\n",
    "\n",
    "        self._memory = ReplayBuffer(param.buffer_limit)\n",
    "        self._policy_network = None\n",
    "        self._target_network = None\n",
    "        \n",
    "        \n",
    "        if path:\n",
    "            self.load(path)\n",
    "        else:\n",
    "            self._policy_network = Qnet()\n",
    "            self._target_network = Qnet()\n",
    "\n",
    "            self.update_network()\n",
    "\n",
    "        self._optimizer = optim.Adam(self._policy_network.parameters(), lr=param.learning_rate)\n",
    "\n",
    "    def update_network(self):\n",
    "        self._target_network.load_state_dict(self._policy_network.state_dict())\n",
    "\n",
    "    def predict(self, state, epsilon):\n",
    "\n",
    "        out = self._policy_network(state.unsqueeze(0))\n",
    "        r = random.random()\n",
    "\n",
    "        # epsilon greedy\n",
    "        if r < epsilon:\n",
    "            return random.randint(0, 8)\n",
    "        else:\n",
    "            return out.argmax().item()\n",
    "\n",
    "    def step(self, env, state, action):\n",
    "\n",
    "        state_prime, reward, done, info = env.step(action)\n",
    "\n",
    "        self._memory.put(\n",
    "            state=state,\n",
    "            state_prime=state_prime,\n",
    "            action=action,\n",
    "            reward=reward,\n",
    "            done=done\n",
    "        )\n",
    "\n",
    "        return state_prime, reward, done, info\n",
    "\n",
    "    def train(self):\n",
    "        state_list, action_list, reward_list, state_prime_list, \\\n",
    "        done_mask_list = self._memory.sample(self._PARAMETER.batch_size)\n",
    "\n",
    "        output = self._policy_network(state_list)\n",
    "        q_action = output.gather(1, action_list)\n",
    "\n",
    "        max_q_prime = self._target_network(state_prime_list).max(1)[0].unsqueeze(1)\n",
    "        target = reward_list + self._PARAMETER.gamma * max_q_prime * done_mask_list\n",
    "\n",
    "        loss = F.smooth_l1_loss(q_action, target)\n",
    "\n",
    "        self._optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self._policy_network.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self._policy_network = Qnet()\n",
    "        self._target_network = Qnet()\n",
    "\n",
    "        self._policy_network.load_state_dict(torch.load(path))\n",
    "        self._policy_network.eval()\n",
    "\n",
    "        self._memory.reset()\n",
    "\n",
    "        self.update_network()\n",
    "\n",
    "\n",
    "class Environment(gym.Wrapper):\n",
    "    move = 0\n",
    "    eat = 50\n",
    "    death = -1000\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Environment, self).__init__(gym.make('MsPacman-v0'))\n",
    "\n",
    "        self._move_reward = Environment.move\n",
    "        self._eat_reward = Environment.eat\n",
    "        self._death_reward = Environment.death\n",
    "\n",
    "        self._metadata = None\n",
    "\n",
    "    def reset(self,\n",
    "              reward_move: int = move,\n",
    "              reward_eat: int = eat,\n",
    "              reward_death: int = death,\n",
    "              **kwargs):\n",
    "\n",
    "        self._move_reward = reward_move\n",
    "        self._eat_reward = reward_eat\n",
    "        self._death_reward = reward_death\n",
    "\n",
    "        state = super(Environment, self).reset(**kwargs)\n",
    "        return self.observation(state)\n",
    "\n",
    "    def step(self, action):\n",
    "        state_prime, reward, done, info = super(Environment, self).step(action)\n",
    "\n",
    "        state_prime = self.observation(state_prime)\n",
    "        reward = self.reward(reward, info)\n",
    "\n",
    "        self._metadata = info\n",
    "\n",
    "        return state_prime, reward, done, info\n",
    "\n",
    "    def reward(self, reward, info):\n",
    "\n",
    "        new_reward = 0\n",
    "\n",
    "        # move\n",
    "        if reward == 0:\n",
    "            new_reward = self._move_reward\n",
    "        # eat\n",
    "        elif reward == 10:\n",
    "            new_reward = self._eat_reward\n",
    "\n",
    "        if self._metadata and self._metadata['lives'] > info['lives']:\n",
    "            new_reward -= 1000\n",
    "\n",
    "        return new_reward\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = observation[1:172, 1:160]\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((84, 84)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        return transform(observation)\n",
    "\n",
    "\n",
    "\n",
    "savefile = '20220516121000.pt'\n",
    "\n",
    "def main():\n",
    "\n",
    "    parameter = HyperParameter(\n",
    "        batch_size=32,\n",
    "        buffer_limit=50000,\n",
    "        gamma=0.98,\n",
    "        learning_rate=0.1\n",
    "    )\n",
    "    \n",
    "    \n",
    "    env = Environment()\n",
    "    agent = DQNAgent(param=parameter, path=savefile)\n",
    "\n",
    "    print_interval = 20\n",
    "    score = 0.0\n",
    "\n",
    "    for n_epi in range(100000):\n",
    "        epsilon = 0.5\n",
    "        \n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        episode_score = 0\n",
    "        \n",
    "        while not done:\n",
    "            action = agent.predict(state, epsilon)\n",
    "            state_prime, reward, done, info = agent.step(env, state, action)\n",
    "            print(action)\n",
    "            state = state_prime\n",
    "            \n",
    "            score += reward   \n",
    "            episode_score += reward\n",
    "            \n",
    "            import time\n",
    "            \n",
    "            time.sleep(0.01)\n",
    "            \n",
    "            env.render()\n",
    "            \n",
    "        print(episode_score)\n",
    "            \n",
    "        if n_epi % print_interval == 0 and n_epi != 0:\n",
    "            agent.update_network()\n",
    "\n",
    "            print(\"n_episode :{}, score : {:.1f}, eps : {:.1f}%\".format(\n",
    "                n_epi, score / print_interval, epsilon * 100))\n",
    "            score = 0.0\n",
    "\n",
    "main()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3215894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759c4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96718a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-learn",
   "language": "python",
   "name": "rl-learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
