{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a12d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ca8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=500\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c370e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "render = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf3c8c",
   "metadata": {},
   "source": [
    "### CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c4bf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PTECH\\anaconda3\\envs\\rl-learn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import collections\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import threading\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "gamma = 0.98\n",
    "buffer_limit = 50000\n",
    "batch_size = 32\n",
    "\n",
    "result = []\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "\n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        state_list, action_list, reward_list, state_prime_list, done_mask_list = [], [], [], [], []\n",
    "\n",
    "        for transition in mini_batch:\n",
    "            state, action, reward, state_prime, done_mask = transition\n",
    "\n",
    "            state_list.append(state)\n",
    "            action_list.append([action])\n",
    "            reward_list.append([reward])\n",
    "            state_prime_list.append(state_prime)\n",
    "            done_mask_list.append([done_mask])\n",
    "\n",
    "        return torch.stack(state_list), torch.tensor(action_list), \\\n",
    "               torch.tensor(reward_list), torch.stack(state_prime_list), \\\n",
    "               torch.tensor(done_mask_list)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "\n",
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self._conv1 = nn.Conv2d(3, 16, (5, 3))\n",
    "        # self.bn1 = nn.BatchNorm2d(16)\n",
    "        self._max_pool1 = nn.MaxPool2d(kernel_size=(3, 2))\n",
    "\n",
    "        self._conv2 = nn.Conv2d(16, 32, (5, 3))\n",
    "        self._max_pool2 = nn.MaxPool2d(kernel_size=(3, 2))\n",
    "        # self.bn2 = nn.BatchNorm2d(32)\n",
    "        self._conv3 = nn.Conv2d(32, 32, (5, 3))\n",
    "        # self.bn3 = nn.BatchNorm2d(32)\n",
    "        self._max_pool3 = nn.MaxPool2d(kernel_size=(3, 2))\n",
    "\n",
    "        self._ln1 = nn.Linear(2304, 64)\n",
    "        self._ln2 = nn.Linear(64, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self._conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self._max_pool1(x)\n",
    "\n",
    "        x = self._conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self._max_pool2(x)\n",
    "\n",
    "        x = self._conv3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self._max_pool3(x)\n",
    "\n",
    "        if x.dim() == 3:\n",
    "            x = x.view(-1)\n",
    "        else:\n",
    "            x = x.view(batch_size, -1)\n",
    "\n",
    "        x = self._ln1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self._ln2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0, 8)\n",
    "        else:\n",
    "            return out.argmax().item()\n",
    "\n",
    "\n",
    "def train(q_network, target_network, memory, optimizer):\n",
    "    state_list, action_list, reward_list, state_prime_list, \\\n",
    "    done_mask_list = memory.sample(batch_size)\n",
    "\n",
    "    output = q_network(state_list)\n",
    "    q_action = output.gather(1, action_list)\n",
    "\n",
    "\n",
    "    max_q_prime = target_network(state_prime_list).max(1)[0].unsqueeze(1)\n",
    "    target = reward_list + gamma * max_q_prime * done_mask_list\n",
    "    loss = F.smooth_l1_loss(q_action, target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def preproess_state(state):\n",
    "    state = state[1:172, 1:160]\n",
    "    r = state[:, :, 0]\n",
    "    g = state[:, :, 1]\n",
    "    b = state[:, :, 2]\n",
    "\n",
    "    return np.asarray([r, g, b])\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    env = gym.make('MsPacman-v0')\n",
    "\n",
    "    q_network = Qnet()\n",
    "    target_network = Qnet()\n",
    "    target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "    memory = ReplayBuffer()\n",
    "\n",
    "    print_interval = 20\n",
    "    score = 0.0\n",
    "    optimizer = optim.Adam(q_network.parameters(), lr=learning_rate)\n",
    "    \n",
    "    global render\n",
    "\n",
    "    for n_epi in range(10000):\n",
    "        epsilon = max(0.01, 0.5 - 0.01 * (n_epi / 20))\n",
    "\n",
    "        state = env.reset()\n",
    "        state = torch.tensor(preproess_state(state)).float()\n",
    "        done = False\n",
    "        \n",
    "        action_list = []\n",
    "        episode_reward = 0\n",
    "        \n",
    "        current_lives = 3\n",
    "        \n",
    "        while not done:\n",
    "\n",
    "            # 순전파를 통한 액션 도출\n",
    "            action = q_network.sample_action(state, epsilon)\n",
    "            state_prime, reward, done, info = env.step(action)\n",
    "            \n",
    "            action_list.append(action)\n",
    "            \n",
    "            reward = -1 if reward == 0 else reward\n",
    "            reward = 50 if reward == 10 else reward\n",
    "            \n",
    "            if info['lives'] < current_lives:\n",
    "                reward -= 1000\n",
    "                current_lives = info['lives']\n",
    "            \n",
    "            \n",
    "            state_prime = torch.tensor(preproess_state(state_prime)).float()\n",
    "            \n",
    "            done_mask = 0.0 if done else 1.0\n",
    "                        \n",
    "            memory.put((state, action, reward, state_prime, done_mask))\n",
    "            state = state_prime\n",
    "\n",
    "            episode_reward += reward\n",
    "\n",
    "            if render:\n",
    "                env.render()\n",
    "                import time\n",
    "                time.sleep(0.01)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        if memory.size() > 2000:\n",
    "            # 순전파, 역전파를 통한 학습\n",
    "            train(q_network, target_network, memory, optimizer)\n",
    "        \n",
    "        result.append({\n",
    "            'action_list': action_list,\n",
    "            'reward': episode_reward,\n",
    "            'epsilon': epsilon\n",
    "        })\n",
    "        \n",
    "        score += episode_reward\n",
    "        \n",
    "\n",
    "        if n_epi % print_interval == 0 and n_epi != 0:\n",
    "            target_network.load_state_dict(q_network.state_dict())\n",
    "            print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
    "                n_epi, score / print_interval, memory.size(), epsilon * 100))\n",
    "            score = 0.0\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "threading.Thread(target=main).start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "849d09f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_list</th>\n",
       "      <th>reward</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3, 3, 3, 3, 1, 3, 3, 3, 4, 3, 4, 3, 3, 4, 3, 3, 1, 0, 8, 3, 3, 4, 0, 8, 8, 3, 3, 5, 7, 3, 3, 7, 3, 3, 3, 4, 3, 7, 8, 4, 3, 1, 3, 3, 3, 3, 3, 0, 4, 8, 4, 3, 6, 3, 3, 7, 3, 3, 3, 3, 3, 3, 0, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 3, 3, 3, 7, 2, 3, 4, 3, 8, 6, 8, 7, 4, 3, 3, 1, 3, 3, 3, 3, 2, 3, 7, 3, 3, 3, 3, ...]</td>\n",
       "      <td>-1886.0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 3, 8, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 3, 3, 7, 3, 3, 3, 3, 7, 3, 4, 8, 3, 3, 0, 2, 0, 6, 3, 1, 3, 0, 4, 3, 7, 2, 1, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 2, 1, 4, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 7, 3, 3, 6, 8, 3, 3, 3, 3, 3, 8, 3, 3, 3, 7, 3, 2, 5, 8, 8, 3, 3, 3, 1, 3, ...]</td>\n",
       "      <td>-2615.0</td>\n",
       "      <td>0.4995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                         action_list  \\\n",
       "0  [3, 3, 3, 3, 1, 3, 3, 3, 4, 3, 4, 3, 3, 4, 3, 3, 1, 0, 8, 3, 3, 4, 0, 8, 8, 3, 3, 5, 7, 3, 3, 7, 3, 3, 3, 4, 3, 7, 8, 4, 3, 1, 3, 3, 3, 3, 3, 0, 4, 8, 4, 3, 6, 3, 3, 7, 3, 3, 3, 3, 3, 3, 0, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 3, 3, 3, 7, 2, 3, 4, 3, 8, 6, 8, 7, 4, 3, 3, 1, 3, 3, 3, 3, 2, 3, 7, 3, 3, 3, 3, ...]   \n",
       "1  [0, 3, 8, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 3, 3, 7, 3, 3, 3, 3, 7, 3, 4, 8, 3, 3, 0, 2, 0, 6, 3, 1, 3, 0, 4, 3, 7, 2, 1, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 2, 1, 4, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 7, 3, 3, 6, 8, 3, 3, 3, 3, 3, 8, 3, 3, 3, 7, 3, 2, 5, 8, 8, 3, 3, 3, 1, 3, ...]   \n",
       "\n",
       "   reward  epsilon  \n",
       "0 -1886.0   0.5000  \n",
       "1 -2615.0   0.4995  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "668d4cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode :20, score : -2160.9, n_buffer : 17580, eps : 49.0%\n",
      "n_episode :40, score : -2283.5, n_buffer : 34893, eps : 48.0%\n",
      "n_episode :60, score : -2198.1, n_buffer : 50000, eps : 47.0%\n",
      "n_episode :80, score : -2234.3, n_buffer : 50000, eps : 46.0%\n",
      "n_episode :100, score : -2124.1, n_buffer : 50000, eps : 45.0%\n",
      "n_episode :120, score : -2283.2, n_buffer : 50000, eps : 44.0%\n",
      "n_episode :140, score : -2133.2, n_buffer : 50000, eps : 43.0%\n",
      "n_episode :160, score : -2155.6, n_buffer : 50000, eps : 42.0%\n",
      "n_episode :180, score : -1937.3, n_buffer : 50000, eps : 41.0%\n",
      "n_episode :200, score : -1947.4, n_buffer : 50000, eps : 40.0%\n",
      "n_episode :220, score : -2225.8, n_buffer : 50000, eps : 39.0%\n",
      "n_episode :240, score : -2332.8, n_buffer : 50000, eps : 38.0%\n",
      "n_episode :260, score : -2339.6, n_buffer : 50000, eps : 37.0%\n",
      "n_episode :280, score : -1923.0, n_buffer : 50000, eps : 36.0%\n",
      "n_episode :300, score : -2208.0, n_buffer : 50000, eps : 35.0%\n",
      "n_episode :320, score : -2103.2, n_buffer : 50000, eps : 34.0%\n",
      "n_episode :340, score : -2234.3, n_buffer : 50000, eps : 33.0%\n",
      "n_episode :360, score : -1906.3, n_buffer : 50000, eps : 32.0%\n",
      "n_episode :380, score : -2330.7, n_buffer : 50000, eps : 31.0%\n",
      "n_episode :400, score : -2157.6, n_buffer : 50000, eps : 30.0%\n",
      "n_episode :420, score : -1920.0, n_buffer : 50000, eps : 29.0%\n",
      "n_episode :440, score : -2461.4, n_buffer : 50000, eps : 28.0%\n",
      "n_episode :460, score : -2030.0, n_buffer : 50000, eps : 27.0%\n",
      "n_episode :480, score : -2079.8, n_buffer : 50000, eps : 26.0%\n",
      "n_episode :500, score : -2306.2, n_buffer : 50000, eps : 25.0%\n",
      "n_episode :520, score : -2436.3, n_buffer : 50000, eps : 24.0%\n",
      "n_episode :540, score : -2007.9, n_buffer : 50000, eps : 23.0%\n",
      "n_episode :560, score : -2129.3, n_buffer : 50000, eps : 22.0%\n",
      "n_episode :580, score : -2197.3, n_buffer : 50000, eps : 21.0%\n",
      "n_episode :600, score : -2313.3, n_buffer : 50000, eps : 20.0%\n",
      "n_episode :620, score : -1682.8, n_buffer : 50000, eps : 19.0%\n",
      "n_episode :640, score : -2460.8, n_buffer : 50000, eps : 18.0%\n",
      "n_episode :660, score : -2398.3, n_buffer : 50000, eps : 17.0%\n",
      "n_episode :680, score : -1998.6, n_buffer : 50000, eps : 16.0%\n",
      "n_episode :700, score : -2233.1, n_buffer : 50000, eps : 15.0%\n",
      "n_episode :720, score : -2186.7, n_buffer : 50000, eps : 14.0%\n",
      "n_episode :740, score : -2281.6, n_buffer : 50000, eps : 13.0%\n",
      "n_episode :760, score : -2085.1, n_buffer : 50000, eps : 12.0%\n",
      "n_episode :780, score : -2516.7, n_buffer : 50000, eps : 11.0%\n",
      "n_episode :800, score : -2184.6, n_buffer : 50000, eps : 10.0%\n",
      "n_episode :820, score : -2451.4, n_buffer : 50000, eps : 9.0%\n",
      "n_episode :840, score : -2040.8, n_buffer : 50000, eps : 8.0%\n",
      "n_episode :860, score : -2533.8, n_buffer : 50000, eps : 7.0%\n",
      "n_episode :880, score : -2507.2, n_buffer : 50000, eps : 6.0%\n",
      "n_episode :900, score : -2322.5, n_buffer : 50000, eps : 5.0%\n",
      "n_episode :920, score : -2592.4, n_buffer : 50000, eps : 4.0%\n",
      "n_episode :940, score : -2474.5, n_buffer : 50000, eps : 3.0%\n",
      "n_episode :960, score : -3070.2, n_buffer : 50000, eps : 2.0%\n",
      "n_episode :980, score : -3062.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1000, score : -2876.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1020, score : -2538.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1040, score : -2947.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1060, score : -3049.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1080, score : -2922.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1100, score : -2731.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1120, score : -3048.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1140, score : -2559.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1160, score : -3144.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1180, score : -2872.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1200, score : -3092.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1220, score : -2823.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1240, score : -2907.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1260, score : -2908.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1280, score : -3037.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1300, score : -2745.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1320, score : -2818.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1340, score : -2997.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1360, score : -3160.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1380, score : -2935.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1400, score : -2573.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1420, score : -2983.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1440, score : -3119.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1460, score : -2844.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1480, score : -3041.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1500, score : -2607.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1520, score : -2896.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1540, score : -3120.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1560, score : -2899.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1580, score : -2525.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1600, score : -2816.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1620, score : -2463.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1640, score : -2637.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1660, score : -3069.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1680, score : -2929.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1700, score : -2857.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1720, score : -2780.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1740, score : -2945.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1760, score : -2972.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1780, score : -2890.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1800, score : -2931.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1820, score : -2705.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1840, score : -3086.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1860, score : -2705.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1880, score : -2687.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1900, score : -2702.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1920, score : -2634.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1940, score : -2778.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1960, score : -2894.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1980, score : -3062.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2000, score : -2925.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2020, score : -2700.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2040, score : -3124.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2060, score : -2706.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2080, score : -2885.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2100, score : -2751.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2120, score : -2985.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2140, score : -2939.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2160, score : -2991.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2180, score : -2545.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2200, score : -2900.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2220, score : -2848.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2240, score : -2927.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2260, score : -2746.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2280, score : -3051.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2300, score : -2636.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2320, score : -2862.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2340, score : -2926.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2360, score : -2895.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2380, score : -2764.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2400, score : -2871.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2420, score : -2844.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2440, score : -2682.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2460, score : -2814.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2480, score : -2725.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2500, score : -2891.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2520, score : -2747.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2540, score : -2951.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2560, score : -2782.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2580, score : -2771.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2600, score : -2730.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2620, score : -3009.5, n_buffer : 50000, eps : 1.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode :2640, score : -2748.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2660, score : -2591.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2680, score : -2879.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2700, score : -2817.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2720, score : -2838.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2740, score : -2801.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2760, score : -2624.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2780, score : -3047.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2800, score : -2750.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2820, score : -2625.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2840, score : -2446.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2860, score : -2772.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2880, score : -3005.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2900, score : -2865.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2920, score : -2814.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2940, score : -2899.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2960, score : -2913.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2980, score : -2960.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3000, score : -2927.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3020, score : -3037.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3040, score : -2691.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3060, score : -2952.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3080, score : -2481.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3100, score : -2542.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3120, score : -2746.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3140, score : -2625.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3160, score : -2761.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3180, score : -2583.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3200, score : -2914.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3220, score : -2772.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3240, score : -2671.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3260, score : -2872.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3280, score : -2967.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3300, score : -3036.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3320, score : -2503.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3340, score : -2558.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3360, score : -2489.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3380, score : -2894.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3400, score : -2939.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3420, score : -3009.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3440, score : -2726.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3460, score : -2762.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3480, score : -2887.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3500, score : -2848.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3520, score : -2708.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3540, score : -2750.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3560, score : -2743.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3580, score : -3087.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3600, score : -2546.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3620, score : -3067.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3640, score : -2530.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3660, score : -2782.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3680, score : -2708.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3700, score : -3014.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3720, score : -2926.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3740, score : -2820.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3760, score : -2656.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3780, score : -2857.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3800, score : -2718.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3820, score : -2871.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3840, score : -2750.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3860, score : -2963.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3880, score : -2943.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3900, score : -2775.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3920, score : -2761.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3940, score : -2911.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3960, score : -2672.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3980, score : -2944.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4000, score : -2749.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4020, score : -2721.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4040, score : -2841.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4060, score : -2771.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4080, score : -2943.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4100, score : -2777.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4120, score : -2796.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4140, score : -2854.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4160, score : -2954.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4180, score : -2676.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4200, score : -2840.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4220, score : -2659.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4240, score : -2671.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4260, score : -2719.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4280, score : -2781.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4300, score : -2854.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4320, score : -2902.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4340, score : -2890.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4360, score : -2770.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4380, score : -2739.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4400, score : -2904.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4420, score : -2858.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4440, score : -2869.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4460, score : -2856.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4480, score : -2481.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4500, score : -2959.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4520, score : -2661.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4540, score : -2794.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4560, score : -2703.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4580, score : -2690.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4600, score : -2893.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4620, score : -2729.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4640, score : -2862.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4660, score : -2853.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4680, score : -2917.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4700, score : -2835.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4720, score : -2661.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4740, score : -3029.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4760, score : -2968.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4780, score : -2848.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4800, score : -3068.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4820, score : -2862.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4840, score : -2860.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4860, score : -2552.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4880, score : -2824.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4900, score : -2586.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4920, score : -2851.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4940, score : -2976.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4960, score : -2655.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4980, score : -2827.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5000, score : -2917.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5020, score : -2992.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5040, score : -2796.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5060, score : -2774.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5080, score : -2986.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5100, score : -2653.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5120, score : -2814.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5140, score : -2656.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5160, score : -2902.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5180, score : -2937.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5200, score : -2708.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5220, score : -3075.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5240, score : -2735.3, n_buffer : 50000, eps : 1.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode :5260, score : -2726.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5280, score : -2560.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5300, score : -2711.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5320, score : -2762.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5340, score : -2880.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5360, score : -2574.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5380, score : -2711.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5400, score : -3018.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5420, score : -2757.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5440, score : -2818.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5460, score : -3070.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5480, score : -2906.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5500, score : -2896.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5520, score : -2993.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5540, score : -2741.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5560, score : -2933.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5580, score : -2758.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5600, score : -3113.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5620, score : -2737.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5640, score : -2724.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5660, score : -3012.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5680, score : -2988.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5700, score : -2551.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5720, score : -2611.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5740, score : -2756.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5760, score : -2730.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5780, score : -2636.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5800, score : -2774.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5820, score : -2605.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5840, score : -2767.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5860, score : -2821.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5880, score : -2814.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5900, score : -2669.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5920, score : -2985.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5940, score : -2898.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5960, score : -3069.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5980, score : -2896.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6000, score : -2941.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6020, score : -2856.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6040, score : -2869.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6060, score : -2567.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6080, score : -2881.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6100, score : -2835.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6120, score : -2769.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6140, score : -2885.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6160, score : -2684.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6180, score : -2466.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6200, score : -2778.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6220, score : -2663.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6240, score : -2869.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6260, score : -3029.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6280, score : -2790.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6300, score : -2678.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6320, score : -2806.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6340, score : -3056.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6360, score : -2831.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6380, score : -2871.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6400, score : -3089.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6420, score : -2634.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6440, score : -2803.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6460, score : -2665.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6480, score : -2878.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6500, score : -2677.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6520, score : -2891.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6540, score : -2790.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6560, score : -2830.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6580, score : -2756.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6600, score : -2712.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6620, score : -2805.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6640, score : -2811.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6660, score : -2541.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6680, score : -2595.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6700, score : -2593.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6720, score : -2600.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6740, score : -2543.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6760, score : -2741.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6780, score : -2799.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6800, score : -2755.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6820, score : -2777.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6840, score : -2763.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6860, score : -2824.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6880, score : -2412.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6900, score : -2898.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6920, score : -2768.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6940, score : -2837.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6960, score : -2892.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6980, score : -2839.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7000, score : -2660.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7020, score : -2632.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7040, score : -2750.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7060, score : -2522.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7080, score : -2664.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7100, score : -2927.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7120, score : -2739.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7140, score : -2809.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7160, score : -2685.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7180, score : -2510.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7200, score : -2621.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7220, score : -2884.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7240, score : -2938.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7260, score : -2996.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7280, score : -2796.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7300, score : -2863.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7320, score : -2804.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7340, score : -2835.8, n_buffer : 50000, eps : 1.0%\n"
     ]
    }
   ],
   "source": [
    "render = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613614f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c4eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c5cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0661d4f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6272\\3275756190.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa90536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b76306",
   "metadata": {},
   "outputs": [],
   "source": [
    "render = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"result-{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d725c1",
   "metadata": {},
   "source": [
    "2770    [4, 1, 7, 0, 2, 5, 5, 0, 3, 5, 7, 8, 5, 7, 3, 3, 5, 1, 5, 5, 5, 7, 4, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 3, 6, 7, 5, 5, 5, 4, 0, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 4, 5, 0, 5, 2, 5, 5, 4, 5, 5, 5, 5, 1, 0, 3, 5, 5, 0, 4, 6, 8, 4, 8, 5, 0, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 3, 5, 5, 2, 5, 4, 5, 5, ...]\n",
    "Name: action_list, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13216519",
   "metadata": {},
   "source": [
    "### VIEW MAX SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('result-20220510175834.csv')\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97711bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = log[log['reward'] == log['reward'].max()]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "action_list = ast.literal_eval(row['action_list'].values[0])\n",
    "action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc3453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PTECH\\anaconda3\\envs\\rl-learn\\lib\\site-packages\\gym\\envs\\atari\\environment.py:269: UserWarning: \u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "  \"We strongly suggest supplying `render_mode` when \"\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('MsPacman-v0')\n",
    "env.reset()\n",
    "\n",
    "\n",
    "for action in action_list:\n",
    "    env.step(action)\n",
    "    env.render()\n",
    "    \n",
    "    import time\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3215894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759c4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-learn",
   "language": "python",
   "name": "rl-learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
